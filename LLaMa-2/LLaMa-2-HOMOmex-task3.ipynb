{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbf265d9-f4ba-4aa6-b217-2ac543d556eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch,os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48cb6f0e-b21a-4b51-967f-26be260e672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Llama-2\"\n",
    "model_name_or_path = \"meta-llama/Llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31853dc4-2979-4735-834c-93b4ec6a56ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_length_input=196\n",
    "lr = 2e-4\n",
    "num_epochs = 5\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce7711-79cf-440a-9c01-cd63d326000b",
   "metadata": {},
   "source": [
    "# Model init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc57661c-2383-4c7f-b656-62d46d72d966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itp1hc/.conda/envs/thinSA/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-04-28 07:39:16.988899: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-28 07:39:16.989003: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-28 07:39:17.020641: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-28 07:39:17.109042: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-28 07:39:19.537322: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.47s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import AutoTokenizer, GenerationConfig, TextStreamer, pipeline, AutoModelForSeq2SeqLM,LlamaTokenizerFast\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path,cache_dir=\"Thin/llms\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,torch_dtype=torch.bfloat16,\n",
    "                                              device_map=\"auto\",cache_dir=\"Thin/llms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3417d684-160d-41be-99e2-c1cfb507fc7a",
   "metadata": {},
   "source": [
    "# Run experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889d3720-f1d9-47c2-9b44-5f612b8963ea",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e57251a-f7a0-412b-b94f-a35b9cc395b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Verso 1]\\nNo sé si tu boca está besando a otr...</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El tiempo se ha pasado\\nY yo no sé nada de ti\\...</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Me haces sentir que quiera ser mejor.\\nMe hace...</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Introducción]\\nWu! Ja, ja, wu\\n[Verso]\\nYa no...</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yo me pregunto porque sera\\nNos gusta sufrir\\n...</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics label\n",
       "0  [Verso 1]\\nNo sé si tu boca está besando a otr...    NP\n",
       "1  El tiempo se ha pasado\\nY yo no sé nada de ti\\...    NP\n",
       "2  Me haces sentir que quiera ser mejor.\\nMe hace...    NP\n",
       "3  [Introducción]\\nWu! Ja, ja, wu\\n[Verso]\\nYa no...    NP\n",
       "4  Yo me pregunto porque sera\\nNos gusta sufrir\\n...    NP"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_train = 'dataset/Homomexican/track_3_train.csv'\n",
    "path_dev = 'dataset/Homomexican/track_3_dev.csv'\n",
    "path_test = 'dataset/Homomexican/track_3_public_test.csv'\n",
    "path_output = \"./Output/SA/HSA/\"\n",
    "\n",
    "import pandas as pd\n",
    "data_train = pd.read_csv(path_train)\n",
    "data_train.reset_index(drop=True, inplace=True)\n",
    "#id_train = data_train['id_EXIST'].tolist()\n",
    "\n",
    "data_test= pd.read_csv(path_test)\n",
    "data_test.reset_index(drop=True, inplace=True)\n",
    "id_test = data_test[\"sub_id\"].tolist()\n",
    "\n",
    "data_dev= pd.read_csv(path_dev)\n",
    "data_dev.reset_index(drop=True, inplace=True)\n",
    "#id_dev = data_dev[\"id_EXIST\"].tolist()\n",
    "\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427cde57-b3ad-45fa-87cb-511cd80022da",
   "metadata": {},
   "source": [
    "# Preprocessing tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdc327ad-cce3-4ad9-be08-3d6c4f1a9c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_part(my_string):    \n",
    "    #my_string = \"This is a string\\nwith multiple lines\\nand we want to split it.\"\n",
    "\n",
    "    # Split the string by newlines\n",
    "    lines = my_string.splitlines()\n",
    "\n",
    "    # the desired number of parts\n",
    "    num_parts = 4\n",
    "\n",
    "    # Split the lines into parts of approximately equal length\n",
    "    parts = []\n",
    "    for i in range(num_parts-1):\n",
    "        start = i * (len(lines) // num_parts)\n",
    "        end = (i + 1) * (len(lines) // num_parts)\n",
    "        parts.append('\\n'.join(lines[start:end]))\n",
    "\n",
    "    start = 3 * (len(lines) // num_parts)\n",
    "    end = len(lines)\n",
    "    parts.append('\\n'.join(lines[start:end]))\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60cc6d23-e825-4bdc-bb60-62d5f3a9998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_train[data_train[\"label\"]=='P']\n",
    "new_lyrics = []\n",
    "label = [\"P\"]*234\n",
    "for index, item in enumerate(data[\"lyrics\"]):\n",
    "    part = split_part(item)\n",
    "    for i in part:\n",
    "        new_lyrics.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00fd5067-939f-4462-ac93-590342800822",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [\"P\"]*len(new_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ce9063a-f769-4866-b35b-2d1ef8aba7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Intro: Babo]\\nVolvió el Don Vergas\\nBien rela...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eso lo saben de sobra, bien sabido desde siemp...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No me diga dónde hay si yo soy el que la trae\\...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vaya-vaya (Vaya-vaya), oye-oye (Oye-oye)\\nUn d...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Muy muy lejos de aquí\\nEn una galaxia\\nEl pode...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics label\n",
       "0  [Intro: Babo]\\nVolvió el Don Vergas\\nBien rela...     P\n",
       "1  Eso lo saben de sobra, bien sabido desde siemp...     P\n",
       "2  No me diga dónde hay si yo soy el que la trae\\...     P\n",
       "3  Vaya-vaya (Vaya-vaya), oye-oye (Oye-oye)\\nUn d...     P\n",
       "4  Muy muy lejos de aquí\\nEn una galaxia\\nEl pode...     P"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augu_data = pd.DataFrame({'lyrics': new_lyrics,\n",
    "                      'label': label})\n",
    "augu_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44809111-de45-45eb-8277-e73f0bec4366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.concat([data_train, augu_data])\n",
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "956ba9de-df03-4cae-a3c3-d3c2b3829d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[\"label\"].tolist().count(\"P\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c1f1353-a0f4-445f-a9f4-29ed8aecafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instruction + output prompt contain all task\n",
    "import re\n",
    "def create_instruction_input_output(df):\n",
    "    input_text = []\n",
    "    output_text = []\n",
    "    inputs = df[\"lyrics\"].tolist()\n",
    "    output = df[\"label\"].tolist()\n",
    "    for index, item in enumerate(inputs):     \n",
    "        item = re.sub(r\"[\\r\\n]+\", \". \", item) #replace all type of white space by a single space   \n",
    "        \n",
    "        prompt_new = f\"\"\"[INST]\n",
    "Classify the sentiment of a following lyrics from a song:\n",
    "{item[:1000]}\n",
    "## if the lyrics directed against any person whose sexual orientation and/or gender identity differs form cis-heterosexuality, output \"P\"\n",
    "## if the lyrics not include any hate speech against the LGBT+ population but do mention this comunity, output \"NP\".\n",
    "Answer: [/INST]\"\"\"     \n",
    "        input_text.append(prompt_new)\n",
    "        output_text.append(output[index])\n",
    "    print(len(input_text),len(output_text))\n",
    "    return input_text,output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f87478cd-d589-4489-a2f8-b326d6c11690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1140 1140\n",
      "[INST]\n",
      "Classify the sentiment of a following lyrics from a song:\n",
      "[Introducción]. Wu! Ja, ja, wu. [Verso]. Ya no te haré llorar, ya no te haré sufrir. Prometo seriamente no volver a molestarte. Ni andar tocando tu ventana para hablarte. Duerme tranquila ya no vuelvo a molestarte. [Puente]. Tú se feliz con quien tú quieras, mientras tanto. Yo voy tratando poco a poco de olvidarte. [Pre-Estribillo]. Fueron tan hermosas. Todas esas noches, todos esos días. Que sinceramente. Fue lo más hermoso de toda mi vida. [Estribillo]. Qué lástima que nuestro amor haya acabado. Y que feliz me sentiré cuando te vea. Que eres feliz con otro amor y que te quiera. Pues tú mereces ser feliz con quien tú quieras. [Interludio]. ¡Y arriba Juárez!. ¡Arriba!. [Pre-Estribillo]. Fueron tan hermosas. Todas esas noches, todos esos días. Que sinceramente. Fue lo más hermoso de toda mi vida. [Estribillo]. Qué lástima que nuestro amor haya acabado. Y que feliz me sentiré cuando te vea. Que eres feliz con otro amor y que te quiera. Pues tú mereces todo y yo. [Verso]. Ya no te haré ll\n",
      "## if the lyrics directed against any person whose sexual orientation and/or gender identity differs form cis-heterosexuality, output \"P\"\n",
      "## if the lyrics not include any hate speech against the LGBT+ population but do mention this comunity, output \"NP\".\n",
      "Answer: [/INST]\n",
      "NP\n"
     ]
    }
   ],
   "source": [
    "# Create instruction input ouput for each task\n",
    "input_train,output_train = create_instruction_input_output(data_train)\n",
    "print(input_train[3])\n",
    "print(output_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9aa5b052-a951-47aa-b231-02823e7d0d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[INST]\\nClassify the sentiment of a following ...</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[INST]\\nClassify the sentiment of a following ...</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[INST]\\nClassify the sentiment of a following ...</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[INST]\\nClassify the sentiment of a following ...</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[INST]\\nClassify the sentiment of a following ...</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[INST]\\nClassify the sentiment of a following ...</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  [INST]\\nClassify the sentiment of a following ...    NP\n",
       "1  [INST]\\nClassify the sentiment of a following ...    NP\n",
       "2  [INST]\\nClassify the sentiment of a following ...    NP\n",
       "3  [INST]\\nClassify the sentiment of a following ...    NP\n",
       "4  [INST]\\nClassify the sentiment of a following ...    NP\n",
       "5  [INST]\\nClassify the sentiment of a following ...    NP"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(list(zip(input_train, output_train)), columns =['text', 'label'])\n",
    "# # removing rows that contain \"UNKNOWN\" OR \"\"-\"\"\n",
    "# train_df = train_df[(train_df[\"label\"] != \"-\") & (train_df[\"label\"] != \"UNKNOWN\")]\n",
    "train_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12bca27c-abc5-4262-aa81-4e701732a27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1140\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary datatype contain train, val set\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "d1s = Dataset.from_pandas(train_df)\n",
    "\n",
    "dataset = DatasetDict()\n",
    "dataset['train'] = d1s\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00821f08-be87-4c60-920a-c55f347fb476",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c233631-4a71-4afa-96d9-2e602df97c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cbad82e-f9ac-45c3-b370-e51199c00588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91f5a58d-15ad-4f87-a6f9-bc6d14361eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 19988480 || all params: 6758404096 || trainable%: 0.2957573965106688\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        inference_mode=False,\n",
    "        r=8, # Lora attention dimension.\n",
    "        lora_alpha=16, # the alpha parameter for Lora scaling.\n",
    "        lora_dropout=0.05, # the dropout probability for Lora layers.\n",
    "        bias=\"none\",\n",
    "        target_modules=[\n",
    "            #\"embed_tokens\",\n",
    "            \"q_proj\",\n",
    "            \"k_proj\",\n",
    "            \"v_proj\",\n",
    "            \"o_proj\",\n",
    "            \"gate_proj\",\n",
    "            \"up_proj\",\n",
    "            \"down_proj\",\n",
    "            #\"lm_head\",\n",
    "        ]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91ac15d9-2863-4327-933b-f596327dce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "\n",
    "# data preprocessing\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "# max_length = max([len(tokenizer(review)[\"input_ids\"]) for review in df1[\"x_input\"][100:200].tolist()])\n",
    "# print(max_length)\n",
    "max_length = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b913db7a-7c6b-45b7-8f47-f72224e866fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset: 100%|██████████| 1140/1140 [00:00<00:00, 2828.61 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    batch_size = len(examples[\"text\"])\n",
    "    inputs = [item + \" \" for item in examples[\"text\"]]\n",
    "    targets = examples[\"label\"]\n",
    "    model_inputs = tokenizer(inputs)\n",
    "    labels = tokenizer(targets, add_special_tokens=False)  # don't add bos token because we concatenate with inputs\n",
    "    for i in range(batch_size):\n",
    "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        label_input_ids = labels[\"input_ids\"][i] + [tokenizer.eos_token_id]\n",
    "        \n",
    "        # print(i, sample_input_ids, label_input_ids)\n",
    "        model_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n",
    "        labels[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n",
    "        model_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n",
    "    # print(model_inputs)\n",
    "    for i in range(batch_size):\n",
    "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        label_input_ids = labels[\"input_ids\"][i]\n",
    "\n",
    "        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (max_length - len(sample_input_ids)) + sample_input_ids\n",
    "        model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\"attention_mask\"][i]\n",
    "        labels[\"input_ids\"][i] = [-100] * (max_length - len(sample_input_ids)) + label_input_ids\n",
    "        \n",
    "        model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n",
    "        model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n",
    "        labels[\"input_ids\"][i] = torch.tensor(labels[\"input_ids\"][i][:max_length])\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "processed_datasets = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=dataset[f\"train\"].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "\n",
    "#train_dataset = processed_datasets[\"train\"]\n",
    "train_dataset = processed_datasets[f\"train\"]\n",
    "#eval_dataset = processed_datasets[\"test\"]\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",
    ")\n",
    "#eval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d337fcf8-4e10-433e-8c1b-ff12136e2c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [02:54<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0: train_ppl=tensor(1.2057, device='cuda:0') train_epoch_loss=tensor(0.1870, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [02:52<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1: train_ppl=tensor(1.0670, device='cuda:0') train_epoch_loss=tensor(0.0648, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [02:52<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2: train_ppl=tensor(1.0274, device='cuda:0') train_epoch_loss=tensor(0.0270, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [02:52<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3: train_ppl=tensor(1.0065, device='cuda:0') train_epoch_loss=tensor(0.0065, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 285/285 [02:52<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4: train_ppl=tensor(1.0022, device='cuda:0') train_epoch_loss=tensor(0.0022, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "\n",
    "# optimizer and lr scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
    ")\n",
    "\n",
    "# training and evaluation\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        #         print(batch)\n",
    "        #         print(batch[\"input_ids\"].shape)\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.detach().float()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # model.eval()\n",
    "    # eval_loss = 0\n",
    "    # eval_preds = []\n",
    "#     for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "#         batch = {k: v.to(device) for k, v in batch.items()}\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(**batch)\n",
    "#         loss = outputs.loss\n",
    "#         eval_loss += loss.detach().float()\n",
    "#         eval_preds.extend(\n",
    "#             tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n",
    "#         )\n",
    "\n",
    "#     eval_epoch_loss = eval_loss / len(eval_dataloader)\n",
    "#     eval_ppl = torch.exp(eval_epoch_loss)\n",
    "    train_epoch_loss = total_loss / len(train_dataloader)\n",
    "    train_ppl = torch.exp(train_epoch_loss)\n",
    "    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=}\") #{eval_ppl=} {eval_epoch_loss=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0952f17-e823-4481-94fc-7ff472e113b2",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d2ede17-dd41-40e1-b3f0-163b734dd7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(sample,max_len_input=max_length):\n",
    "    inputs = tokenizer(sample, return_tensors=\"pt\").to('cuda')\n",
    "    generation_config  = GenerationConfig(\n",
    "    do_sample=True,\n",
    "    max_new_tokens=128,\n",
    "    top_k=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    penalty_alpha = 0.6,\n",
    "    return_full_text=False,\n",
    "    )\n",
    "    \n",
    "    outputs = model.generate(**inputs, generation_config=generation_config)\n",
    "    output = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    output = output[0].split(\"[/INST]\")[1].strip()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "141d0cf2-fe21-4c6f-a7d0-bfbcc2bdbfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instruction + output prompt contain all task\n",
    "import re\n",
    "def create_instruction_input(df):\n",
    "    input_text = []\n",
    "    inputs = df[\"lyrics\"].tolist()\n",
    "    for index, item in enumerate(inputs):     \n",
    "        item = re.sub(r\"[\\r\\n]+\", \". \", item) #replace all type of white space by a single space   \n",
    "        \n",
    "        prompt_new = f\"\"\"[INST]\n",
    "Classify the sentiment of a following lyrics from a song:\n",
    "{item[:1000]}\n",
    "## if the lyrics directed against any person whose sexual orientation and/or gender identity differs form cis-heterosexuality, output \"P\"\n",
    "## if the lyrics not include any hate speech against the LGBT+ population but do mention this comunity, output \"NP\".\n",
    "Answer: [/INST]\"\"\"\n",
    "        input_text.append(prompt_new)\n",
    "    print(len(input_text))\n",
    "    return input_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5c1211-c7fb-4367-82dc-78431e5754c9",
   "metadata": {},
   "source": [
    "## PREDICTION ON TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "069f635a-f1a6-4a77-b956-a1dbb19f0be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\n"
     ]
    }
   ],
   "source": [
    "test_input = create_instruction_input(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a3af110-32c3-454e-b629-dde4132f04fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:52<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\n",
      "['NP', 'NP', 'NP', 'NP', 'NP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "#predict one batch of datadev at a time\n",
    "for sample in tqdm(test_input):\n",
    "    pred = evaluate_model(sample)\n",
    "    y_pred.append(pred)\n",
    "\n",
    "print(len(y_pred))\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2385a4ed-261a-4618-8912-9c61334844cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_Track3</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_Track3</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_Track3</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_Track3</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4_Track3</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sub_id label\n",
       "0  0_Track3    NP\n",
       "1  1_Track3    NP\n",
       "2  2_Track3    NP\n",
       "3  3_Track3    NP\n",
       "4  4_Track3    NP"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame({'sub_id': id_test,\n",
    "                      'label': y_pred})\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccd77be5-b884-4b66-a1ff-c66650505fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(f'homomex31test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae871b8a-6a46-491c-9522-8b24e1352043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 244\n",
      "246\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.count(\"P\"), y_pred.count(\"NP\"))\n",
    "print(y_pred.count(\"P\") + y_pred.count(\"NP\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6d244fd-550d-4f0d-8df4-5dd2d7011281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ec00c-1650-4aff-8b45-2993db1e333b",
   "metadata": {},
   "source": [
    "## PREDICTION ON DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd3d354a-040f-4bb7-8651-d938052b387a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "dev_input = create_instruction_input(data_dev)\n",
    "dev_output = data_dev[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e4127fa-90cd-4705-8aae-6cfd54d3007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [02:05<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "['NP', 'NP', 'NP', 'NP', 'NP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_dev = []\n",
    "\n",
    "#predict one batch of datadev at a time\n",
    "for sample in tqdm(dev_input):\n",
    "    pred = evaluate_model(sample)\n",
    "    y_pred_dev.append(pred)\n",
    "\n",
    "print(len(y_pred_dev))\n",
    "print(y_pred_dev[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75d85234-95c0-446e-84e8-808fe17d3be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'homomex31dev.txt', 'w') as f: \n",
    "    for word in y_pred_dev: \n",
    "        f.write(f'{word}\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44890e4a-64f5-4ab3-8d7f-c134136cca9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e90dae1-d255-4f39-9385-2fb30f9b014d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 568\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_dev.count(\"P\"), y_pred_dev.count(\"NP\"))\n",
    "print(y_pred_dev.count(\"P\") + y_pred_dev.count(\"NP\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bafbd4-89fc-41ea-80c2-cfd11bf7dd07",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfba997b-c613-4114-92e6-4a401c8df87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NP       0.95      0.96      0.96       560\n",
      "           P       0.38      0.30      0.33        40\n",
      "\n",
      "    accuracy                           0.92       600\n",
      "   macro avg       0.66      0.63      0.65       600\n",
      "weighted avg       0.91      0.92      0.92       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "print(classification_report(data_dev[\"label\"].tolist(), y_pred_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b5754-dad4-4315-b2f6-b6982263a9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thinSA",
   "language": "python",
   "name": "thinsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
