{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbf265d9-f4ba-4aa6-b217-2ac543d556eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch,os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48cb6f0e-b21a-4b51-967f-26be260e672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Llama-2\"\n",
    "model_name_or_path = \"meta-llama/Llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31853dc4-2979-4735-834c-93b4ec6a56ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-4\n",
    "num_epochs = 5\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce7711-79cf-440a-9c01-cd63d326000b",
   "metadata": {},
   "source": [
    "# Model init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc57661c-2383-4c7f-b656-62d46d72d966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itp1hc/.conda/envs/thinSA/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-04-28 05:13:45.250824: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-28 05:13:45.250923: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-28 05:13:45.278808: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-28 05:13:45.353864: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-28 05:13:47.537425: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.39s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import AutoTokenizer, GenerationConfig, TextStreamer, pipeline, AutoModelForSeq2SeqLM,LlamaTokenizerFast\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path,cache_dir=\"Thin/llms\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,torch_dtype=torch.bfloat16,\n",
    "                                              device_map=\"auto\",cache_dir=\"Thin/llms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3417d684-160d-41be-99e2-c1cfb507fc7a",
   "metadata": {},
   "source": [
    "# Run experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889d3720-f1d9-47c2-9b44-5f612b8963ea",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e57251a-f7a0-412b-b94f-a35b9cc395b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sub_id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0_Track2</td>\n",
       "      <td>Es más chida la gente transfóbica que lo acept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1_Track2</td>\n",
       "      <td>A él ni lo menciones porque es joto. Jajaja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2_Track2</td>\n",
       "      <td>Tenemos a la directiva más puta marica del fút...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3_Track2</td>\n",
       "      <td>@ThierryHenry marica! ¿Ya olvidaste como celeb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4_Track2</td>\n",
       "      <td>@EPN   Chinga a tu madre maricón de mierda, tu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    sub_id                                            content\n",
       "0           0  0_Track2  Es más chida la gente transfóbica que lo acept...\n",
       "1           1  1_Track2        A él ni lo menciones porque es joto. Jajaja\n",
       "2           2  2_Track2  Tenemos a la directiva más puta marica del fút...\n",
       "3           3  3_Track2  @ThierryHenry marica! ¿Ya olvidaste como celeb...\n",
       "4           4  4_Track2  @EPN   Chinga a tu madre maricón de mierda, tu..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_train = 'dataset/Homomexican/track_2_train.csv'\n",
    "path_dev = 'dataset/Homomexican/track_2_dev.csv'\n",
    "path_test = 'dataset/Homomexican/track_2_public_test.csv'\n",
    "path_output = \"./Output/SA/HSA/\"\n",
    "\n",
    "import pandas as pd\n",
    "data_train = pd.read_csv(path_train)\n",
    "#data_train.reset_index(drop=True, inplace=False)\n",
    "#id_train = data_train['id_EXIST'].tolist()\n",
    "\n",
    "data_test= pd.read_csv(path_test)\n",
    "#data_test.reset_index(drop=True, inplace=False)\n",
    "id_test = data_test[\"sub_id\"].tolist()\n",
    "\n",
    "data_dev= pd.read_csv(path_dev)\n",
    "#data_dev.reset_index(drop=True, inplace=False)\n",
    "#id_dev = data_dev[\"id_EXIST\"].tolist()\n",
    "\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427cde57-b3ad-45fa-87cb-511cd80022da",
   "metadata": {},
   "source": [
    "# Preprocessing tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77e97b56-207e-4c3d-a532-5718e08214a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalize_hashtag(doc):\n",
    "    new_text = re.sub(r\"#\\w+\\s*\", \"\", doc, flags=re.MULTILINE) # first remove all hashtag and followed word in tweet\n",
    "    pattern = r\"(?=[A-Z 0-9])\"\n",
    "    for hashtag in re.findall(r\"(?:\\#)\\S+\", doc): #for each hashtag in text\n",
    "        if not hashtag.isupper(): # if that hashtag is not fully upper case\n",
    "            split = re.split(pattern, hashtag) #split that hashtag by upper case letter, example: GamerGirl -> Gamer Girl\n",
    "            hashtag = ' '.join(str(x) for x in split if len(str(x))>1) #some bad case: AMDRedTeam -> A M D Red Team. The only thing we could do is removing any single letter in that text\n",
    "        new_word = re.sub(r'#',\"\", hashtag, flags=re.MULTILINE) #remove \"#\" in text\n",
    "        new_text = f\"{new_text} {new_word}\" # adding processed hashtag back to tweet\n",
    "    return new_text\n",
    "\n",
    "data_train['content'] = data_train['content'].apply(normalize_hashtag)\n",
    "data_dev['content'] = data_dev['content'].apply(normalize_hashtag)\n",
    "data_test['content'] = data_test['content'].apply(normalize_hashtag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680caee9-0ae4-4416-86ad-a874bf5e5503",
   "metadata": {},
   "source": [
    "# preprocessing label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3528b40e-b219-4e7a-91d8-9767f943c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['label'] = data_train[data_train.columns[2:]].values.tolist()\n",
    "data_dev['label'] = data_dev[data_dev.columns[1:]].values.tolist()\n",
    "def id2label(id_):\n",
    "    label = ['LES','GAY','BI','TRAN','OTHER','NOT RELATED']\n",
    "    out_label = []\n",
    "    for index, i in enumerate(id_):\n",
    "        if i == 1:\n",
    "            out_label.append(label[index])\n",
    "    return ', '.join(out_label)\n",
    "\n",
    "data_train['label'] = data_train['label'].apply(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c25115e-beb8-4a95-a6c1-47f9b4114bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instruction + output prompt contain all task\n",
    "import re\n",
    "def create_instruction_input_output(df):\n",
    "    input_text = []\n",
    "    output_text = []\n",
    "    inputs = df[\"content\"].tolist()\n",
    "    output = df[\"label\"].tolist()\n",
    "    for index, item in enumerate(inputs):     \n",
    "        item = re.sub(r\"\\s+\", \" \", item) #replace all type of white space by a single space   \n",
    "        \n",
    "        prompt_new = f\"\"\"[INST]\n",
    "Predict one or more labels of a tweet: \"{item}\"\n",
    "## if the tweet contain hate speech directed at homosexual people who identify as female, output \"LES\"\n",
    "## if the tweet contain hate speech directed at homosexual people who identify as male, output \"GAY\".\n",
    "## if the tweet directed at people who attracted to more than one gender, output \"BI\".\n",
    "## if the tweet against transgender, output \"TRAN\".\n",
    "## if the tweet against other sexual and gender minorities, output \"OTHER\".\n",
    "## if the tweet are not related in any way, output \"NOT RELATED\". OUTPUT only the labels, nothing else.\n",
    "Answer: [/INST]\"\"\"     \n",
    "        input_text.append(prompt_new)\n",
    "        output_text.append(output[index])\n",
    "    print(len(input_text),len(output_text))\n",
    "    return input_text,output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b13f14f4-12c9-428b-a3dd-1086771674bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1071 1071\n",
      "[INST]\n",
      "Predict one or more labels of a tweet: \"No llore jota\"\n",
      "## if the tweet contain hate speech directed at homosexual people who identify as female, output \"LES\"\n",
      "## if the tweet contain hate speech directed at homosexual people who identify as male, output \"GAY\".\n",
      "## if the tweet directed at people who attracted to more than one gender, output \"BI\".\n",
      "## if the tweet against transgender, output \"TRAN\".\n",
      "## if the tweet against other sexual and gender minorities, output \"OTHER\".\n",
      "## if the tweet are not related in any way, output \"NOT RELATED\". OUTPUT only the labels, nothing else.\n",
      "Answer: [/INST]\n",
      "GAY\n"
     ]
    }
   ],
   "source": [
    "# Create instruction input ouput for each task\n",
    "input_train,output_train = create_instruction_input_output(data_train)\n",
    "print(input_train[3])\n",
    "print(output_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caa656ff-a092-4db9-9f5c-78d131e273c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[INST]\\nPredict one or more labels of a tweet:...</td>\n",
       "      <td>LES, GAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[INST]\\nPredict one or more labels of a tweet:...</td>\n",
       "      <td>GAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[INST]\\nPredict one or more labels of a tweet:...</td>\n",
       "      <td>GAY, OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[INST]\\nPredict one or more labels of a tweet:...</td>\n",
       "      <td>GAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[INST]\\nPredict one or more labels of a tweet:...</td>\n",
       "      <td>GAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[INST]\\nPredict one or more labels of a tweet:...</td>\n",
       "      <td>GAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       label\n",
       "0  [INST]\\nPredict one or more labels of a tweet:...    LES, GAY\n",
       "1  [INST]\\nPredict one or more labels of a tweet:...         GAY\n",
       "2  [INST]\\nPredict one or more labels of a tweet:...  GAY, OTHER\n",
       "3  [INST]\\nPredict one or more labels of a tweet:...         GAY\n",
       "4  [INST]\\nPredict one or more labels of a tweet:...         GAY\n",
       "5  [INST]\\nPredict one or more labels of a tweet:...         GAY"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(list(zip(input_train, output_train)), columns =['text', 'label'])\n",
    "# # removing rows that contain \"UNKNOWN\" OR \"\"-\"\"\n",
    "# train_df = train_df[(train_df[\"label\"] != \"-\") & (train_df[\"label\"] != \"UNKNOWN\")]\n",
    "train_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12bca27c-abc5-4262-aa81-4e701732a27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1071\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary datatype contain train, val set\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "d1s = Dataset.from_pandas(train_df)\n",
    "\n",
    "dataset = DatasetDict()\n",
    "dataset['train'] = d1s\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00821f08-be87-4c60-920a-c55f347fb476",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c233631-4a71-4afa-96d9-2e602df97c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cbad82e-f9ac-45c3-b370-e51199c00588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91f5a58d-15ad-4f87-a6f9-bc6d14361eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 19988480 || all params: 6758404096 || trainable%: 0.2957573965106688\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        inference_mode=False,\n",
    "        r=8, # Lora attention dimension.\n",
    "        lora_alpha=16, # the alpha parameter for Lora scaling.\n",
    "        lora_dropout=0.05, # the dropout probability for Lora layers.\n",
    "        bias=\"none\",\n",
    "        target_modules=[\n",
    "            #\"embed_tokens\",\n",
    "            \"q_proj\",\n",
    "            \"k_proj\",\n",
    "            \"v_proj\",\n",
    "            \"o_proj\",\n",
    "            \"gate_proj\",\n",
    "            \"up_proj\",\n",
    "            \"down_proj\",\n",
    "            #\"lm_head\",\n",
    "        ]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91ac15d9-2863-4327-933b-f596327dce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "\n",
    "# data preprocessing\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "# max_length = max([len(tokenizer(review)[\"input_ids\"]) for review in df1[\"x_input\"][100:200].tolist()])\n",
    "# print(max_length)\n",
    "max_length = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b913db7a-7c6b-45b7-8f47-f72224e866fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset: 100%|██████████| 1071/1071 [00:00<00:00, 3176.35 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    batch_size = len(examples[\"text\"])\n",
    "    inputs = [item + \" \" for item in examples[\"text\"]]\n",
    "    targets = examples[\"label\"]\n",
    "    model_inputs = tokenizer(inputs)\n",
    "    labels = tokenizer(targets, add_special_tokens=False)  # don't add bos token because we concatenate with inputs\n",
    "    for i in range(batch_size):\n",
    "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        label_input_ids = labels[\"input_ids\"][i] + [tokenizer.eos_token_id]\n",
    "        \n",
    "        # print(i, sample_input_ids, label_input_ids)\n",
    "        model_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n",
    "        labels[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n",
    "        model_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n",
    "    # print(model_inputs)\n",
    "    for i in range(batch_size):\n",
    "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        label_input_ids = labels[\"input_ids\"][i]\n",
    "\n",
    "        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (max_length - len(sample_input_ids)) + sample_input_ids\n",
    "        model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\"attention_mask\"][i]\n",
    "        labels[\"input_ids\"][i] = [-100] * (max_length - len(sample_input_ids)) + label_input_ids\n",
    "        \n",
    "        model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n",
    "        model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n",
    "        labels[\"input_ids\"][i] = torch.tensor(labels[\"input_ids\"][i][:max_length])\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "processed_datasets = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    remove_columns=dataset[f\"train\"].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "\n",
    "#train_dataset = processed_datasets[\"train\"]\n",
    "train_dataset = processed_datasets[f\"train\"]\n",
    "#eval_dataset = processed_datasets[\"test\"]\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",
    ")\n",
    "#eval_dataloader = DataLoader(eval_dataset, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d337fcf8-4e10-433e-8c1b-ff12136e2c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [02:42<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0: train_ppl=tensor(1.2316, device='cuda:0') train_epoch_loss=tensor(0.2083, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [02:42<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1: train_ppl=tensor(1.0955, device='cuda:0') train_epoch_loss=tensor(0.0912, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [02:42<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2: train_ppl=tensor(1.0590, device='cuda:0') train_epoch_loss=tensor(0.0573, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [02:42<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3: train_ppl=tensor(1.0339, device='cuda:0') train_epoch_loss=tensor(0.0333, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [02:42<00:00,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4: train_ppl=tensor(1.0161, device='cuda:0') train_epoch_loss=tensor(0.0160, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "\n",
    "# optimizer and lr scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
    ")\n",
    "\n",
    "# training and evaluation\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        #         print(batch)\n",
    "        #         print(batch[\"input_ids\"].shape)\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.detach().float()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # model.eval()\n",
    "    # eval_loss = 0\n",
    "    # eval_preds = []\n",
    "#     for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "#         batch = {k: v.to(device) for k, v in batch.items()}\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(**batch)\n",
    "#         loss = outputs.loss\n",
    "#         eval_loss += loss.detach().float()\n",
    "#         eval_preds.extend(\n",
    "#             tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n",
    "#         )\n",
    "\n",
    "#     eval_epoch_loss = eval_loss / len(eval_dataloader)\n",
    "#     eval_ppl = torch.exp(eval_epoch_loss)\n",
    "    train_epoch_loss = total_loss / len(train_dataloader)\n",
    "    train_ppl = torch.exp(train_epoch_loss)\n",
    "    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=}\") #{eval_ppl=} {eval_epoch_loss=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0952f17-e823-4481-94fc-7ff472e113b2",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d2ede17-dd41-40e1-b3f0-163b734dd7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(sample,max_len_input=max_length):\n",
    "    inputs = tokenizer(sample, return_tensors=\"pt\").to('cuda')\n",
    "    generation_config  = GenerationConfig(\n",
    "    do_sample=True,\n",
    "    max_new_tokens=128,\n",
    "    top_k=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    penalty_alpha = 0.6,\n",
    "    return_full_text=False,\n",
    "    )\n",
    "    \n",
    "    outputs = model.generate(**inputs, generation_config=generation_config)\n",
    "    output = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    output = output[0].split(\"[/INST]\")[1].strip()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69099a5b-257f-4849-8ecf-109ec54220d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instruction + output prompt contain all task\n",
    "import re\n",
    "def create_instruction_input(df):\n",
    "    input_text = []\n",
    "    output_text = []\n",
    "    inputs = df[\"content\"].tolist()\n",
    "    for index, item in enumerate(inputs):     \n",
    "        item = re.sub(r\"\\s+\", \" \", item) #replace all type of white space by a single space   \n",
    "        \n",
    "        prompt_new = f\"\"\"[INST]\n",
    "Predict one or more labels of a tweet: \"{item}\"\n",
    "## if the tweet contain hate speech directed at homosexual people who identify as female, output \"LES\"\n",
    "## if the tweet contain hate speech directed at homosexual people who identify as male, output \"GAY\".\n",
    "## if the tweet directed at people who attracted to more than one gender, output \"BI\".\n",
    "## if the tweet against transgender, output \"TRAN\".\n",
    "## if the tweet against other sexual and gender minorities, output \"OTHER\".\n",
    "## if the tweet are not related in any way, output \"NOT RELATED\". OUTPUT only the labels, nothing else.\n",
    "Answer: [/INST]\"\"\"\n",
    "        input_text.append(prompt_new)\n",
    "    print(len(input_text))\n",
    "    return input_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5c1211-c7fb-4367-82dc-78431e5754c9",
   "metadata": {},
   "source": [
    "## PREDICTION ON TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72e63ac8-7007-4667-9a5f-1f2d25f617c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n"
     ]
    }
   ],
   "source": [
    "test_input = create_instruction_input(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a3af110-32c3-454e-b629-dde4132f04fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [01:09<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n",
      "['TRAN', 'GAY', 'GAY', 'GAY', 'GAY']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "#predict one batch of datadev at a time\n",
    "for sample in tqdm(test_input):\n",
    "    pred = evaluate_model(sample)\n",
    "    y_pred.append(pred)\n",
    "\n",
    "print(len(y_pred))\n",
    "print(y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2385a4ed-261a-4618-8912-9c61334844cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_Track2</td>\n",
       "      <td>TRAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_Track2</td>\n",
       "      <td>GAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_Track2</td>\n",
       "      <td>GAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_Track2</td>\n",
       "      <td>GAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4_Track2</td>\n",
       "      <td>GAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sub_id label\n",
       "0  0_Track2  TRAN\n",
       "1  1_Track2   GAY\n",
       "2  2_Track2   GAY\n",
       "3  3_Track2   GAY\n",
       "4  4_Track2   GAY"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame({'sub_id': id_test,\n",
    "                      'label': y_pred,})\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10c4c5d6-57cb-4294-93ae-64be338285bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['label'].tolist().count('NOT RELATED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52aea893-ecef-4179-aa68-6967ab0cbed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2id(out_label):\n",
    "    label = ['LES','GAY','BI','TRAN','OTHER','NOT RELATED']\n",
    "    xlist = out_label.split(\", \")\n",
    "    out_id = [0, 0, 0, 0, 0, 0]\n",
    "    for index, labe in enumerate(label):\n",
    "        if labe in xlist:\n",
    "            out_id[index] = 1\n",
    "    return out_id\n",
    "\n",
    "y_pred_pro = [label2id(i) for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df89be2c-e3f1-4218-a849-2bc9b8e300c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 1, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_pro[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95517755-0034-4976-9100-5d84170331ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_id</th>\n",
       "      <th>L</th>\n",
       "      <th>G</th>\n",
       "      <th>B</th>\n",
       "      <th>T</th>\n",
       "      <th>O</th>\n",
       "      <th>NR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_Track2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_Track2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_Track2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_Track2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4_Track2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sub_id  L  G  B  T  O  NR\n",
       "0  0_Track2  0  0  0  1  0   0\n",
       "1  1_Track2  0  1  0  0  0   0\n",
       "2  2_Track2  0  1  0  0  0   0\n",
       "3  3_Track2  0  1  0  0  0   0\n",
       "4  4_Track2  0  1  0  0  0   0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame({'sub_id': id_test,\n",
    "                      'L': [i[0] for i in y_pred_pro],\n",
    "                       'G': [i[1] for i in y_pred_pro],\n",
    "                       'B': [i[2] for i in y_pred_pro],\n",
    "                       'T': [i[3] for i in y_pred_pro],\n",
    "                       'O': [i[4] for i in y_pred_pro],\n",
    "                       'NR': [i[5] for i in y_pred_pro]})\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae871b8a-6a46-491c-9522-8b24e1352043",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(f'homomex21test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777ec00c-1650-4aff-8b45-2993db1e333b",
   "metadata": {},
   "source": [
    "## PREDICTION ON DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89a3e262-84ab-420f-8b6e-eca18bfab18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862\n"
     ]
    }
   ],
   "source": [
    "dev_input = create_instruction_input(data_dev)\n",
    "dev_output = data_dev[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e4127fa-90cd-4705-8aae-6cfd54d3007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 862/862 [03:48<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862\n",
      "['GAY', 'OTHER', 'GAY', 'GAY', 'GAY']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_dev = []\n",
    "\n",
    "#predict one batch of datadev at a time\n",
    "for sample in tqdm(dev_input):\n",
    "    pred = evaluate_model(sample)\n",
    "    y_pred_dev.append(pred)\n",
    "\n",
    "print(len(y_pred_dev))\n",
    "print(y_pred_dev[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c563b1c2-103e-44b7-9642-588d6df9fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dev_pro = [label2id(i) for i in y_pred_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75d85234-95c0-446e-84e8-808fe17d3be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'Homomex21dev.txt', 'w') as f: \n",
    "    for word in y_pred_dev: \n",
    "        f.write(f'{word}\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44890e4a-64f5-4ab3-8d7f-c134136cca9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "862"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred_dev_pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bafbd4-89fc-41ea-80c2-cfd11bf7dd07",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfba997b-c613-4114-92e6-4a401c8df87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        72\n",
      "           1       1.00      1.00      1.00       714\n",
      "           2       1.00      1.00      1.00        10\n",
      "           3       1.00      1.00      1.00        79\n",
      "           4       0.95      0.91      0.93        64\n",
      "           5       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       1.00      0.99      0.99       939\n",
      "   macro avg       0.83      0.81      0.82       939\n",
      "weighted avg       1.00      0.99      0.99       939\n",
      " samples avg       1.00      0.99      0.99       939\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/itp1hc/.conda/envs/thinSA/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/itp1hc/.conda/envs/thinSA/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "print(classification_report(data_dev[\"label\"].tolist(), y_pred_dev_pro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589ad288-39e7-4975-8b75-1f09daf7f11c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thinSA",
   "language": "python",
   "name": "thinsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
