{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8212188,"sourceType":"datasetVersion","datasetId":4689763}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re, string\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-21T18:51:50.486162Z","iopub.execute_input":"2024-05-21T18:51:50.487005Z","iopub.status.idle":"2024-05-21T18:51:50.495532Z","shell.execute_reply.started":"2024-05-21T18:51:50.486963Z","shell.execute_reply":"2024-05-21T18:51:50.494489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random, torch\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:51:50.497421Z","iopub.execute_input":"2024-05-21T18:51:50.497850Z","iopub.status.idle":"2024-05-21T18:51:50.507857Z","shell.execute_reply.started":"2024-05-21T18:51:50.497772Z","shell.execute_reply":"2024-05-21T18:51:50.507087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:51:50.508936Z","iopub.execute_input":"2024-05-21T18:51:50.509269Z","iopub.status.idle":"2024-05-21T18:51:50.518074Z","shell.execute_reply.started":"2024-05-21T18:51:50.509236Z","shell.execute_reply":"2024-05-21T18:51:50.517347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev_path = '/kaggle/input/track_2_dev.csv'\ntrain_path = '/kaggle/input/public_data_train_phase/track_2_train.csv'","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:51:50.520004Z","iopub.execute_input":"2024-05-21T18:51:50.520540Z","iopub.status.idle":"2024-05-21T18:51:50.528947Z","shell.execute_reply.started":"2024-05-21T18:51:50.520515Z","shell.execute_reply":"2024-05-21T18:51:50.528173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read data","metadata":{}},{"cell_type":"code","source":"import string,re\nimport emoji\n\ndef preprocessing_text(text):\n    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text, flags=re.MULTILINE)\n    text = text.strip()\n    text = text.translate(text.maketrans('', '', string.punctuation.replace(\"_\",\"\")))\n    text = re.sub('\\\\s+',' ',text).strip() #remove white space\n    return text\n\ndef emoji_preprocess(data, column='content'):\n    for index, row in data.iterrows():\n        data.loc[index, column] = emoji.demojize(row['content'], language='es')\n\ndef preprocessing_data(df):\n    df[\"content\"] = df[\"content\"].apply(preprocessing_text)\n    emoji_preprocess(df)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:51:50.529942Z","iopub.execute_input":"2024-05-21T18:51:50.530202Z","iopub.status.idle":"2024-05-21T18:51:50.540566Z","shell.execute_reply.started":"2024-05-21T18:51:50.530180Z","shell.execute_reply":"2024-05-21T18:51:50.539716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:51:50.541667Z","iopub.execute_input":"2024-05-21T18:51:50.541923Z","iopub.status.idle":"2024-05-21T18:51:50.566691Z","shell.execute_reply.started":"2024-05-21T18:51:50.541901Z","shell.execute_reply":"2024-05-21T18:51:50.565921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(train_path)\npreprocessing_data(train_data)\ntrain_data['label'] = train_data[train_data.columns[2:]].values.tolist()\ntrain_data['label'] = train_data['label'].apply(lambda x: np.array(x, dtype='f'))\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:51:50.567680Z","iopub.execute_input":"2024-05-21T18:51:50.567923Z","iopub.status.idle":"2024-05-21T18:51:51.040921Z","shell.execute_reply.started":"2024-05-21T18:51:50.567902Z","shell.execute_reply":"2024-05-21T18:51:51.039839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv(dev_path)\npreprocessing_data(test_data)\ntest_data['label'] = test_data[test_data.columns[1:]].values.tolist()\ntest_data['label'] = test_data['label'].apply(lambda x: np.array(x, dtype='f'))\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:51:51.042651Z","iopub.execute_input":"2024-05-21T18:51:51.042992Z","iopub.status.idle":"2024-05-21T18:51:51.434227Z","shell.execute_reply.started":"2024-05-21T18:51:51.042960Z","shell.execute_reply":"2024-05-21T18:51:51.433136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Classifier","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\nmodel_name = \"FacebookAI/xlm-roberta-base\"\n\nbert_model = AutoModelForSequenceClassification.from_pretrained(model_name, problem_type=\"multi_label_classification\",\n                                                                num_labels=6)\ntokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:52:25.711898Z","iopub.execute_input":"2024-05-21T18:52:25.712301Z","iopub.status.idle":"2024-05-21T18:52:46.034205Z","shell.execute_reply.started":"2024-05-21T18:52:25.712245Z","shell.execute_reply":"2024-05-21T18:52:46.033418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:52:46.036140Z","iopub.execute_input":"2024-05-21T18:52:46.036737Z","iopub.status.idle":"2024-05-21T18:52:46.043759Z","shell.execute_reply.started":"2024-05-21T18:52:46.036699Z","shell.execute_reply":"2024-05-21T18:52:46.042715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import *\nfrom transformers import Trainer, TrainingArguments\n\nprint(train_data.head())\npredicted_targets =[]\nactual_targets = []\ny_train= train_data['label'].tolist()\ny_test= test_data['label'].tolist()\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n#train_data = pd.DataFrame(zip(X_train,y_train),  columns=[\"text\",\"label\"])\n#test_data = pd.DataFrame(zip(X_test,y_test),  columns=[\"text\",\"label\"])\n    \ntrain_encodings = tokenizer(train_data['content'].tolist(), truncation=True, padding=True)\ntest_encodings = tokenizer(test_data['content'].tolist(), truncation=True, padding=True)\n\ntrain_dataset = CustomDataset(train_encodings, y_train)\ntest_dataset = CustomDataset(test_encodings, y_test)\n\ntraining_args = TrainingArguments(\n    output_dir='./results',          # output directory\n    save_strategy = \"epoch\",\n    save_total_limit=1,\n    num_train_epochs=15,              # total number of training epochs\n#   evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,  # batch size per device during training\n    warmup_steps=100,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    logging_steps=100,\n    report_to='tensorboard'\n    )\n\ntrainer = Trainer(\n    model=bert_model,                    # the instantiated ðŸ¤— Transformers model to be trained\n    args=training_args,                  # training arguments, defined above\n    train_dataset=train_dataset,         # training dataset\n#     eval_dataset = test_dataset\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:52:46.045110Z","iopub.execute_input":"2024-05-21T18:52:46.045487Z","iopub.status.idle":"2024-05-21T18:54:17.001771Z","shell.execute_reply.started":"2024-05-21T18:52:46.045445Z","shell.execute_reply":"2024-05-21T18:54:17.000319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_prediction(text,tokenizer,trainer):\n    demo_input = preprocessing_text(text)\n    demo_encodings = tokenizer(demo_input, truncation=True, padding=True, return_tensors=\"pt\")\n    demo_encodings = {k: v.to(trainer.model.device) for k,v in demo_encodings.items()}\n    #test_dataset = CustomDataset(demo_encodings, [0])\n    \n    outputs = trainer.model(**demo_encodings)\n    logits = outputs.logits\n    sigmoid = torch.nn.Sigmoid()\n    probs = sigmoid(logits.squeeze().cpu())\n    predictions = np.zeros(probs.shape)\n    predictions[np.where(probs >= 0.5)] = 1.0    \n    return predictions\n\n\ny_pred=[]\nfor text in test_data['content'].tolist():\n    a = make_prediction(text,tokenizer,trainer)\n    y_pred.append(a)\n    \nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:56:50.214035Z","iopub.execute_input":"2024-05-21T18:56:50.214411Z","iopub.status.idle":"2024-05-21T18:57:00.554120Z","shell.execute_reply.started":"2024-05-21T18:56:50.214381Z","shell.execute_reply":"2024-05-21T18:57:00.553252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}