{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8212188,"sourceType":"datasetVersion","datasetId":4689763}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re, string\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-21T18:59:36.237713Z","iopub.execute_input":"2024-05-21T18:59:36.238502Z","iopub.status.idle":"2024-05-21T18:59:37.257865Z","shell.execute_reply.started":"2024-05-21T18:59:36.238468Z","shell.execute_reply":"2024-05-21T18:59:37.256876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random, torch\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:59:37.259688Z","iopub.execute_input":"2024-05-21T18:59:37.260112Z","iopub.status.idle":"2024-05-21T18:59:41.309054Z","shell.execute_reply.started":"2024-05-21T18:59:37.260084Z","shell.execute_reply":"2024-05-21T18:59:41.308016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:59:41.310291Z","iopub.execute_input":"2024-05-21T18:59:41.310722Z","iopub.status.idle":"2024-05-21T18:59:41.318669Z","shell.execute_reply.started":"2024-05-21T18:59:41.310695Z","shell.execute_reply":"2024-05-21T18:59:41.317633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev_path = '/kaggle/input/homomex24-development/track_3_dev.csv'\ntrain_path = '/kaggle/input/homomex24-development/public_data_train_phase/track_3_train.csv'","metadata":{"execution":{"iopub.status.busy":"2024-05-21T18:59:41.320667Z","iopub.execute_input":"2024-05-21T18:59:41.321011Z","iopub.status.idle":"2024-05-21T18:59:41.328818Z","shell.execute_reply.started":"2024-05-21T18:59:41.320984Z","shell.execute_reply":"2024-05-21T18:59:41.327824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read data","metadata":{}},{"cell_type":"code","source":"def convert_label(label):\n    if label == 'NP':\n        return 0\n    elif label == 'P':\n        return 1\n    else:\n        print('error:', label)\n        return None","metadata":{"execution":{"iopub.status.busy":"2024-05-21T19:01:39.109368Z","iopub.execute_input":"2024-05-21T19:01:39.110091Z","iopub.status.idle":"2024-05-21T19:01:39.114623Z","shell.execute_reply.started":"2024-05-21T19:01:39.110061Z","shell.execute_reply":"2024-05-21T19:01:39.113788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(train_path)\ntrain_data[\"label\"] = train_data[\"label\"].apply(convert_label)\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T19:01:40.888310Z","iopub.execute_input":"2024-05-21T19:01:40.888657Z","iopub.status.idle":"2024-05-21T19:01:40.930431Z","shell.execute_reply.started":"2024-05-21T19:01:40.888632Z","shell.execute_reply":"2024-05-21T19:01:40.929417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv(dev_path)\ntest_data[\"label\"] = test_data[\"label\"].apply(convert_label)\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-21T19:01:43.305267Z","iopub.execute_input":"2024-05-21T19:01:43.306763Z","iopub.status.idle":"2024-05-21T19:01:43.342601Z","shell.execute_reply.started":"2024-05-21T19:01:43.306709Z","shell.execute_reply":"2024-05-21T19:01:43.341189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Classifier","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\nmodel_name = \"FacebookAI/xlm-roberta-base\"\n\nbert_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\ntokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T19:02:02.896219Z","iopub.execute_input":"2024-05-21T19:02:02.896619Z","iopub.status.idle":"2024-05-21T19:02:27.563481Z","shell.execute_reply.started":"2024-05-21T19:02:02.896588Z","shell.execute_reply":"2024-05-21T19:02:27.562127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-21T19:02:27.565835Z","iopub.execute_input":"2024-05-21T19:02:27.566538Z","iopub.status.idle":"2024-05-21T19:02:27.574574Z","shell.execute_reply.started":"2024-05-21T19:02:27.566497Z","shell.execute_reply":"2024-05-21T19:02:27.573156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import *\nfrom transformers import Trainer, TrainingArguments\n\nprint(train_data.head())\npredicted_targets =[]\nactual_targets = []\ny_train= train_data['label'].tolist()\ny_test= test_data['label'].tolist()\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n#train_data = pd.DataFrame(zip(X_train,y_train),  columns=[\"text\",\"label\"])\n#test_data = pd.DataFrame(zip(X_test,y_test),  columns=[\"text\",\"label\"])\n\nprint(\"=============================================================\")\nprint(\"Train\")\nprint(train_data[\"label\"].value_counts())\nprint(\"Test\")\nprint(test_data[\"label\"].value_counts())\nprint(\"=============================================================\")\n    \ntrain_encodings = tokenizer(train_data['lyrics'].tolist(), truncation=True, padding=True)\ntest_encodings = tokenizer(test_data['lyric'].tolist(), truncation=True, padding=True)\n\ntrain_dataset = CustomDataset(train_encodings, y_train)\ntest_dataset = CustomDataset(test_encodings, y_test)\n\ntraining_args = TrainingArguments(\n    output_dir='./results',          # output directory\n    save_strategy = \"epoch\",\n    save_total_limit=1,\n    num_train_epochs=10,              # total number of training epochs\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,  # batch size per device during training\n    warmup_steps=100,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir='./logs',            # directory for storing logs\n    logging_steps=100,\n    report_to='tensorboard'\n    )\n\ntrainer = Trainer(\n    model=bert_model,                    # the instantiated ðŸ¤— Transformers model to be trained\n    args=training_args,                  # training arguments, defined above\n    train_dataset=train_dataset,         # training dataset\n#     eval_dataset = test_dataset\n)\ntrainer.train()\n\npreds = trainer.predict(test_dataset)[0]\ny_pred = np.argmax(preds, axis=1).flatten().tolist()\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-05-21T19:04:12.246583Z","iopub.execute_input":"2024-05-21T19:04:12.247359Z","iopub.status.idle":"2024-05-21T19:05:30.795802Z","shell.execute_reply.started":"2024-05-21T19:04:12.247325Z","shell.execute_reply":"2024-05-21T19:05:30.794673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}